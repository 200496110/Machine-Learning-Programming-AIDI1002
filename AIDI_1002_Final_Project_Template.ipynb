{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title: AIDI 1002 Final Term Project Report\n",
    "\n",
    "#### Rishabh Patadia (200496110)\n",
    "\n",
    "####  Emails: 200496110@student.georgianc.on.ca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction:\n",
    "\n",
    "#### Problem Description:\n",
    "\n",
    "The paper titled, \"Block Hankel Tensor ARIMA for Multiple Short Time Series Forecasting\", proposes a novel idea of using BHT and ARIMA for forecasting time series. This project aims to add more data types and examples to this paper. This paper uses electricity data, traffic data, and sales data for demostraing the new models capability by measuring NRMSE.\n",
    "\n",
    "#### Context of the Problem:\n",
    "\n",
    "Timeseries data prediction is an exteremly important part of AI and Machine Learning. This can be used for many data such as weather, financial markets, sales, marketing, electricity consumption, etc.. So having new ways to predict the data efficiently can always help.\n",
    "\n",
    "#### Limitation About other Approaches:\n",
    "\n",
    "This paper only used the electricity, traffic, and sales data. So its performance on stocks data is not known.\n",
    "\n",
    "#### Solution:\n",
    "\n",
    "This project will try to implement new model and a couple other existing models on the stocks data. This will add a new column in the comparision table for stocks data type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "Explain the related work using the following table\n",
    "\n",
    "| Reference |Explanation |  Dataset/Input |Weakness\n",
    "| --- | --- | --- | --- |\n",
    "| Faloutsos et al. 2019. [1] | Provides a concise and intuitive overview of the most important methods and tools available for solving large-scale forecasting problems. It reviews the state of the art in three related fields: (1) classical modeling of time series, (2) modern methods including tensor analysis and deep learning for forecasting. |  89.05% accuracy | This is mostly a high level overview on how to use the forecasting methods on sample dataset\n",
    "| Yokota et al. 2018 [2] | They consider a low-rank model in an embedded space of a tensor. For this purpose, they extend a delay embedding for a time series to a “multi-way delay-embedding transform” for a tensor, which takes a given incomplete tensor as the input and outputs a higher-order incomplete Hankel tensor. The higher-order tensor is then recovered by Tucker-based low-rank tensor factorization. Finally, an estimated tensor can be obtained by using the inverse multiway delay embedding transform of the recovered higherorder tensor| They have multiple images of a magnetic resonance for a time period, and they randomly remove the images to generate removed slices of image |  They are able to partially generate missing images, but the model is very basic but it has many potential extensions such as using different embedding transformations and constrained tensor decompositions (e.g., non-negative, sparse, and smooth).\n",
    "\n",
    "\n",
    "The last row in this table should be about the method discussed in this paper (If you can't find the weakenss of this method then write about the future improvement, see the future work section of the paper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation\n",
    "\n",
    "In this section, you will provide the code and its explanation. You may have to create more cells after this. (To keep the Notebook clean, do not display debugging output or thousands of print statements from hundreds of epochs. Make sure it is readable for others by reviewing it yourself carefully.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Functions\n",
    "from stock_fetch import stock_fetch\n",
    "from main_edited import get_arima_nrmse\n",
    "from nrmse_arima_xgboost import xgb_nrmse, arima_nrmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 'MSFT' data to stock.csv and stock.npy for last 1 month with 1 hour interval\n"
     ]
    }
   ],
   "source": [
    "# Getting Stock Data\n",
    "stock_fetch(\"MSFT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stock_fetch function takes a ticker such as MSFT for Microsoft, META for Meta/Facebook, TSLA for Tesla, etc.. as argument and saves their stock data in stock.csv and stock.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BHT_ARIMA NRMSE: 0.003855561817295941\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.003855561817295941"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BHT ARIMA NRMSE\n",
    "get_arima_nrmse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The get_arima_nrmse function, reads the stock.npy file and then runs the BHT_ARIMA function on it. And then calculates the NRMSE for and then returns it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBOOST NRMSE: 0.0008460716032492716\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0008460716032492716"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XGB NRMSE\n",
    "xgb_nrmse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The xgb_nrmse function, reads the stock.csv file and then runs the XGB model on it. And then calculates the NRMSE for and then returns it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARIMA NRMSE: 0.004795017181574508\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.004795017181574508"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ARIMA NRMSE\n",
    "arima_nrmse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The arima_nrmse function, reads the stock.csv file and then runs the pmdarima.auto_arima function on it. And then calculates the NRMSE for and then returns it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion and Future Direction\n",
    "\n",
    "In the results we can see that for stock data, our model BHT_ARIMA has a higher mse than XGBOOST. This means that wee need to work more on optimising the hyperparamteres of our model to see if it can outperform XGBOOST on stock data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References:\n",
    "\n",
    "[1] [Faloutsos et al. 2019] Faloutsos, C.; Flunkert, V.; Gasthaus,\n",
    "J.; Januschowski, T.; and Wang, Y. 2019. Forecasting big\n",
    "time series: Theory and practice. In ACM SIGKDD, 3209–\n",
    "3210. ACM.\n",
    "\n",
    "[2] [Yokota et al. 2018] Yokota, T.; Erem, B.; Guler, S.;\n",
    "Warfield, S. K.; and Hontani, H. 2018. Missing slice\n",
    "recovery for tensors using a low-rank model in embedded\n",
    "space. In CVPR, 8251–8259."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
